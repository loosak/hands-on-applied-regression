{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from io import StringIO\n",
    "import zipfile\n",
    "\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn import (dummy, ensemble, linear_model, metrics,\n",
    "                     model_selection, neighbors, neural_network, \n",
    "                     preprocessing, svm, tree)\n",
    "from yellowbrick import features, regressor\n",
    "from yellowbrick import model_selection as ms_yb\n",
    "import xgbfir\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://archive.ics.uci.edu/ml/datasets/Automobile\n",
    "auto_cols = '''symboling\n",
    "normalized-losses\n",
    "make\n",
    "fuel-type\n",
    "aspiration\n",
    "num-of-doors\n",
    "body-style\n",
    "drive-wheels\n",
    "engine-location\n",
    "wheel-base\n",
    "length\n",
    "width\n",
    "height\n",
    "curb-weight\n",
    "engine-type\n",
    "num-of-cylinders\n",
    "engine-size\n",
    "fuel-system\n",
    "bore\n",
    "stroke\n",
    "compression-ratio\n",
    "horsepower\n",
    "peak-rpm\n",
    "city-mpg\n",
    "highway-mpg\n",
    "price'''.split('\\n')\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data'\n",
    "auto = pd.read_csv('../data/imports-85.data', names=auto_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto['num-of-doors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweak_cars(auto):\n",
    "    return (auto\n",
    "            .query('horsepower != \"?\" and price != \"?\"'\n",
    "                  ' and bore != \"?\" and stroke != \"?\"')\n",
    "            .rename({c:c.replace('-', '_') for c in auto.columns}, axis=1)\n",
    "            .replace({'num_of_doors': {'?': 4, 'four': 4, 'two': 2}})\n",
    "            .replace({'num_of_cylinders': {'two': 2, 'three': 3,'four': 4, 'five': 5,\n",
    "                                           'six': 6, 'eight':8, 'twelve':12}})\n",
    "            .assign(horsepower=lambda df: pd.to_numeric(df.horsepower),\n",
    "                    peak_rpm=lambda df: pd.to_numeric(df.peak_rpm),\n",
    "                    price=lambda df: pd.to_numeric(df.price),\n",
    "                    bore=lambda df: pd.to_numeric(df.bore),\n",
    "                    stroke=lambda df: pd.to_numeric(df.stroke))\n",
    "            .drop(columns=['normalized_losses', 'highway_mpg'])\n",
    "            .pipe(lambda df: pd.get_dummies(df, drop_first=True))\n",
    "           )\n",
    "\n",
    "def getX_y(df, y_col):\n",
    "    return df.drop(columns=[y_col]), df[y_col]\n",
    "\n",
    "auto2 = tweak_cars(auto)\n",
    "auto_X, auto_y = getX_y(auto2, 'city_mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto2.plot.scatter(x='horsepower', y='city_mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# very simple\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(auto2[['horsepower']], auto2.city_mpg)\n",
    "lr.score(auto2[['horsepower']], auto2.city_mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = auto2.plot.scatter(x='horsepower', y='city_mpg')\n",
    "xs = np.arange(40, 200)\n",
    "ax.plot(xs, xs*lr.coef_ + lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use all of the columns\n",
    "# Baseline model - default strategy is to always predict mean\n",
    "dm = dummy.DummyRegressor()\n",
    "dm.fit(auto_X, auto_y)\n",
    "dm.score(auto_X, auto_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score is R2 score - coefficient of determintation\n",
    "# Usually between 0-1 - .92 amount that answer is explained by features\n",
    "# 1 - 100% of answer is explained by features\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(auto_X, auto_y)\n",
    "lr.score(auto_X, auto_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(lr.coef_, auto_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Data\n",
    "Ames Housing Dataset\n",
    "http://www.amstat.org/publications/jse/v19n3/decock/AmesHousing.xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Ames Housing Dataset\n",
    "ames_url = '../data/AmesHousing.xls'\n",
    "ames_df = pd.read_excel(ames_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_df2 = (ames_df\n",
    "           .select_dtypes('number')\n",
    "           .dropna()\n",
    "           )\n",
    "ames_X, ames_y = getX_y(ames_df2, 'SalePrice')                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Exercise\n",
    "* Create a regression model for the Ames dataset\n",
    "* What is the \"score\" of your model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_X_y(auto, y_col, size=.3, standardize=True):\n",
    "    \"\"\"We don't want to impute or standardize on the whole dataset\n",
    "    else we are 'leaking' data\"\"\"\n",
    "    y = auto[y_col]\n",
    "    X = auto.drop(columns=y_col)\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "       model_selection.train_test_split(\n",
    "       X, y, test_size=size, random_state=42)\n",
    "    cols = X.columns\n",
    "    X_train = pd.DataFrame(X_train, columns=cols)\n",
    "    X_test = pd.DataFrame(X_test, columns=cols)\n",
    "    if standardize:\n",
    "        std = preprocessing.StandardScaler()\n",
    "        X_train = pd.DataFrame(std.fit_transform(X_train), columns=cols,\n",
    "                              index=y_train.index)\n",
    "        X_test = pd.DataFrame(std.transform(X_test), columns=cols,\n",
    "                             index=y_test.index)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "auto_X_train, auto_X_test, auto_y_train, auto_y_test = \\\n",
    "    get_train_test_X_y(auto2, 'city_mpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model - default strategy is to always predict mean\n",
    "dm = dummy.DummyRegressor()\n",
    "dm.fit(auto_X_train, auto_y_train)\n",
    "dm.score(auto_X_test, auto_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score is R2 score - coefficient of determintation\n",
    "# Usually between 0-1 - .76 amount that answer is explained by features\n",
    "# 1 - 100% of answer is explained by features\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(auto_X_train, auto_y_train)\n",
    "lr.score(auto_X_test, auto_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(auto_X_train, auto_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Exercise\n",
    "* Split the Ames data into a training and testing set\n",
    "* Run a regression model against the new data, what is the score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(auto_X_train, auto_y_train)\n",
    "lr.score(auto_X_test, auto_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(auto_y_test, lr.predict(auto_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average squared error (but can't indicate direction of error)\n",
    "# penalizes large errors\n",
    "metrics.mean_squared_error(auto_y_test, lr.predict(auto_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(auto_y_test, lr.predict(auto_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeRegressor(max_depth=4)\n",
    "dt.fit(auto_X_train, auto_y_train)\n",
    "dt.score(auto_X_test, auto_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(auto_y_test, dt.predict(auto_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(auto_y_test, dt.predict(auto_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals plot \n",
    "# Good for looking at homoskedasticity - variance of errors\n",
    "regressor.residuals_plot(lr, auto_X_train, auto_y_train, auto_X_test, auto_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals plot \n",
    "# Good for looking at homoskedasticity - variance of errors\n",
    "regressor.residuals_plot(dt, auto_X_train, auto_y_train, auto_X_test, auto_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Error \n",
    "# Good for looking at variance and performance at different ends\n",
    "regressor.prediction_error(lr, auto_X_train, auto_y_train, auto_X_test, auto_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Error \n",
    "# Good for looking at variance and performance at different ends\n",
    "regressor.prediction_error(dt, auto_X_train, auto_y_train, auto_X_test, auto_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Exercise\n",
    "* Create a decision tree model for the housing data\n",
    "* Compare the r2 and MSE for the decision tree and linear regression models.\n",
    "* Plot a residuals plot for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeRegressor(max_depth=None)\n",
    "dt.fit(auto_X_train, auto_y_train)\n",
    "dt.score(auto_X_test, auto_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=tree.plot_tree(dt, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "_=tree.plot_tree(dt, max_depth=2, filled=True, feature_names=auto_X.columns, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree.export_text(dt, feature_names=list(auto_X.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model is overfitting\n",
    "# (hint: performs well on training data, but worse on testing)\n",
    "dt.score(auto_X_train, auto_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.score(auto_X_test, auto_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stump = tree.DecisionTreeRegressor(max_depth=1)\n",
    "stump.fit(auto_X_train, auto_y_train)\n",
    "stump.score(auto_X_test, auto_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "_=tree.plot_tree(stump, max_depth=2, filled=True, feature_names=auto_X.columns, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    model = tree.DecisionTreeRegressor(max_depth=i)\n",
    "    model.fit(auto_X_train, auto_y_train)\n",
    "    print(i, model.score(auto_X_test, auto_y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_yb.validation_curve(tree.DecisionTreeRegressor(),  \n",
    "    auto_X, auto_y, param_name='max_depth', param_range=range(1, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# many \"hyperparameters\"\n",
    "stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "param_grid = {'random_state': [42],\n",
    "             'max_depth': [1,2,5,10,20],\n",
    "             'min_impurity_decrease': [0, .1, .2, .5]}\n",
    "grid = model_selection.GridSearchCV(tree.DecisionTreeRegressor(), param_grid=param_grid)\n",
    "grid.fit(auto_X, auto_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_dt = tree.DecisionTreeRegressor(**grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Exercise\n",
    "* Tune a decision tree for the Ames data\n",
    "* What is the score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeRegressor(max_depth=10)\n",
    "dt.fit(auto_X_train, auto_y_train)\n",
    "dt.score(auto_X_test, auto_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "_=tree.plot_tree(dt, max_depth=3, filled=True, feature_names=auto_X.columns, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(dt.feature_importances_, auto_X.columns).sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_yb.feature_importances(dt, auto_X, auto_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shap - Interpret black box models\n",
    "shap_ex = shap.TreeExplainer(dt)\n",
    "vals = shap_ex.shap_values(auto_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.predict(auto_X_test.iloc[[0]])  # prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_y_test.iloc[0]  # actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_X_test.iloc[[0]].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.loc[[148]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horsepower (negative in sample)/price (also negative) increasing mpg\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_ex.expected_value, vals[0, :], feature_names=auto_X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of HP\n",
    "# As HP goes up SHAP goes down (lower mpg)\n",
    "# Shap choose to show bore along with HP (more bore -> more HP)\n",
    "shap.dependence_plot('horsepower', shap_values=vals, features=auto_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Summary of HP (show w/ price)\n",
    "# As HP goes up SHAP goes down (lower mpg)\n",
    "# Price appears to go up as HP goes up\n",
    "shap.dependence_plot('horsepower', shap_values=vals, features=auto_X_test,\n",
    "                    interaction_index='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of features - global view\n",
    "# HP is most important\n",
    "#   As HP goes lower (more blue) shap goes up (as does MPG)\n",
    "shap.summary_plot(vals, auto_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Explaining the model\n",
    "Using a model for the Ames dataset:\n",
    "* What are the most useful features?\n",
    "* Use shap to inspect an individual result\n",
    "* Use shap to inspect the summary of the features\n",
    "* Use shap to inspect an individual feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "Powerful algorithm using \"boosting\" (like golfing) to predict target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeRegressor(max_depth=10)\n",
    "dt.fit(auto_X_train, auto_y_train)\n",
    "dt.score(auto_X_test, auto_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = xgb.XGBRFRegressor()\n",
    "xg.fit(auto_X_train, auto_y_train)\n",
    "xg.score(auto_X_test, auto_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = xg.get_booster()\n",
    "print(booster.get_dump()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = xg.get_booster()\n",
    "print(booster.get_dump()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = xg.get_booster()\n",
    "print(booster.get_dump()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals plot \n",
    "regressor.residuals_plot(xg, auto_X_train, auto_y_train, auto_X_test, auto_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewing interactions\n",
    "xgbfir.saveXgbFI(xg, feature_names=auto_X.columns, OutputXlsxFile='fir-auto.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column impmortance\n",
    "# Gain - total gain of each feature\n",
    "# Fscore - number of splits\n",
    "# wFscore - weighted number of splits (by probability of split taking place)\n",
    "pd.read_excel('fir-auto.xlsx').head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column impmortance\n",
    "# Gain - total gain of each feature\n",
    "# Fscore - number of splits\n",
    "# wFscore - weighted number of splits (by probability of split taking place)\n",
    "pd.read_excel('fir-auto.xlsx', sheet_name='Interaction Depth 1').head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column impmortance\n",
    "# Gain - total gain of each feature\n",
    "# Fscore - number of splits\n",
    "# wFscore - weighted number of splits (by probability of split taking place)\n",
    "pd.read_excel('fir-auto.xlsx', sheet_name='Interaction Depth 2').head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Exercise\n",
    "With the Ames data\n",
    "* Create an XGBoost model\n",
    "* Evaluate the performance. What is the score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
